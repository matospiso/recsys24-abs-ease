{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:34.181452Z",
     "start_time": "2024-05-11T14:15:33.303017Z"
    },
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from dataset import UserSessionItemDataset\n",
    "from evaluation import recall, ndcg, evaluate\n",
    "from models import EASE, AbsEASE\n",
    "from pipelines import hyperparameter_selection, run_test\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb173eaa",
   "metadata": {},
   "source": [
    "# preprocessing = extract away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e499797bcae6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:36.380565Z",
     "start_time": "2024-05-11T14:15:34.192085Z"
    },
    "collapsed": false,
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>brewery_id</th>\n",
       "      <th>brewery_name</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>userId</th>\n",
       "      <th>beer_style</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>beer_name</th>\n",
       "      <th>beer_abv</th>\n",
       "      <th>item_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>sessionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614509</td>\n",
       "      <td>199</td>\n",
       "      <td>Ballast Point Brewing Company</td>\n",
       "      <td>1205561385</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0110x011</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Dorado Double IPA</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10386</td>\n",
       "      <td>2008-03-15 06:09:45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182729</td>\n",
       "      <td>396</td>\n",
       "      <td>AleSmith Brewing Company</td>\n",
       "      <td>1205823873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0110x011</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>YuleSmith (Summer)</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7284</td>\n",
       "      <td>2008-03-18 07:04:33</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1134674</td>\n",
       "      <td>863</td>\n",
       "      <td>Russian River Brewing Company</td>\n",
       "      <td>1207011338</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0110x011</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Pliny The Elder</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7971</td>\n",
       "      <td>2008-04-01 00:55:38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>462893</td>\n",
       "      <td>559</td>\n",
       "      <td>Speakeasy Ales &amp; Lagers</td>\n",
       "      <td>1207362193</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0110x011</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Double Daddy Imperial India Pale Ale</td>\n",
       "      <td>9.5</td>\n",
       "      <td>25283</td>\n",
       "      <td>2008-04-05 02:23:13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>886485</td>\n",
       "      <td>147</td>\n",
       "      <td>Stone Brewing Co.</td>\n",
       "      <td>1208211124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0110x011</td>\n",
       "      <td>American Black Ale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Stone Sublimely Self-Righteous Ale</td>\n",
       "      <td>8.7</td>\n",
       "      <td>38470</td>\n",
       "      <td>2008-04-14 22:12:04</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  brewery_id                   brewery_name   timestamp  rating  \\\n",
       "0   614509         199  Ballast Point Brewing Company  1205561385     1.0   \n",
       "1   182729         396       AleSmith Brewing Company  1205823873     1.0   \n",
       "2  1134674         863  Russian River Brewing Company  1207011338     1.0   \n",
       "3   462893         559        Speakeasy Ales & Lagers  1207362193     1.0   \n",
       "4   886485         147              Stone Brewing Co.  1208211124     1.0   \n",
       "\n",
       "   review_aroma  review_appearance    userId                      beer_style  \\\n",
       "0           4.0                3.5  0110x011  American Double / Imperial IPA   \n",
       "1           5.0                4.0  0110x011  American Double / Imperial IPA   \n",
       "2           5.0                5.0  0110x011  American Double / Imperial IPA   \n",
       "3           4.0                4.0  0110x011  American Double / Imperial IPA   \n",
       "4           5.0                4.0  0110x011              American Black Ale   \n",
       "\n",
       "   review_palate  review_taste                             beer_name  \\\n",
       "0            4.0           4.0                     Dorado Double IPA   \n",
       "1            4.5           4.5                    YuleSmith (Summer)   \n",
       "2            4.5           4.5                       Pliny The Elder   \n",
       "3            3.5           4.0  Double Daddy Imperial India Pale Ale   \n",
       "4            4.0           5.0    Stone Sublimely Self-Righteous Ale   \n",
       "\n",
       "   beer_abv  item_id             datetime  sessionId  \n",
       "0       9.6    10386  2008-03-15 06:09:45          1  \n",
       "1       8.5     7284  2008-03-18 07:04:33          2  \n",
       "2       8.0     7971  2008-04-01 00:55:38          3  \n",
       "3       9.5    25283  2008-04-05 02:23:13          4  \n",
       "4       8.7    38470  2008-04-14 22:12:04          5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "df = pd.read_csv(DATA_FOLDER + 'processedRatingsBeer.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.rename(columns={\"beerId\": \"item_id\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e3b9d1",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df[\"sessionId\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bff4d4d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create a user_session identifier\n",
    "df['user_session_id'] = (df['userId'].astype(str) + '_' + df['sessionId'].astype(str)).map(hash)\n",
    "df = df.sort_values(by=['user_session_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "095679e6",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session_id</th>\n",
       "      <th>userId</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>positiveCount</th>\n",
       "      <th>negativeCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9222769369198958281</td>\n",
       "      <td>nugget</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9222394865684918904</td>\n",
       "      <td>Danny2321</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9222300797394093464</td>\n",
       "      <td>CanonJohn</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9221777287235335041</td>\n",
       "      <td>groovy24</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9221714889734660647</td>\n",
       "      <td>khwheel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24569</th>\n",
       "      <td>9219640372787849508</td>\n",
       "      <td>larshultqvist</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24570</th>\n",
       "      <td>9221344691897703657</td>\n",
       "      <td>russellgillette</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24571</th>\n",
       "      <td>9221473476771149170</td>\n",
       "      <td>beertastegood</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24572</th>\n",
       "      <td>9221758644131394282</td>\n",
       "      <td>Wiiare138</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24573</th>\n",
       "      <td>9223231856449157051</td>\n",
       "      <td>rshwayder</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24574 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           user_session_id           userId  ratingsCount  positiveCount  \\\n",
       "0     -9222769369198958281           nugget             2              2   \n",
       "1     -9222394865684918904        Danny2321             3              2   \n",
       "2     -9222300797394093464        CanonJohn             8              7   \n",
       "3     -9221777287235335041         groovy24             4              4   \n",
       "4     -9221714889734660647          khwheel             1              1   \n",
       "...                    ...              ...           ...            ...   \n",
       "24569  9219640372787849508    larshultqvist             3              3   \n",
       "24570  9221344691897703657  russellgillette             2              2   \n",
       "24571  9221473476771149170    beertastegood             1              1   \n",
       "24572  9221758644131394282        Wiiare138             2              2   \n",
       "24573  9223231856449157051        rshwayder             3              3   \n",
       "\n",
       "       negativeCount  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  0  \n",
       "4                  0  \n",
       "...              ...  \n",
       "24569              0  \n",
       "24570              0  \n",
       "24571              0  \n",
       "24572              0  \n",
       "24573              0  \n",
       "\n",
       "[24574 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testable_sessions = df.groupby('user_session_id').agg({\"userId\": \"first\", \"rating\": \"count\"}).rename(columns={\"rating\": \"ratingsCount\"}).reset_index()\n",
    "testable_sessions[\"positiveCount\"] = 0\n",
    "positive_counts = df[df.rating == 1.].groupby('user_session_id').rating.count()\n",
    "testable_sessions.loc[testable_sessions[\"user_session_id\"].isin(positive_counts.index) ,\"positiveCount\"] = testable_sessions.loc[testable_sessions[\"user_session_id\"].isin(positive_counts.index) ,\"user_session_id\"].apply(lambda x: positive_counts[x])\n",
    "testable_sessions[\"negativeCount\"] = testable_sessions[\"ratingsCount\"] - testable_sessions[\"positiveCount\"]\n",
    "\n",
    "testable_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46afc347",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24574, 32148, 703891)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_session_id.nunique(), df.item_id.nunique(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d509fc",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# testable_sessions = pd.read_csv(DATA_FOLDER + 'testableSessionsBeer.csv')\n",
    "\n",
    "# testable_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f38e764",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24574"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testable_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "335f5874",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2517"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testable_sessions.positiveCount.min())\n",
    "# we need at least 5 positive interactions and 5 negative interactions\n",
    "testable_sessions[\"negativeCount\"] = testable_sessions[\"ratingsCount\"] - testable_sessions[\"positiveCount\"]\n",
    "testable_sessions = testable_sessions[(testable_sessions.positiveCount >= 3) & (testable_sessions.negativeCount >= 3)]\n",
    "len(testable_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3abef52",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# # create a user_session identifier\n",
    "# testable_sessions['user_session_id'] = (testable_sessions['userId'].astype(str) + '_' + testable_sessions['sessionId'].astype(str)).map(hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ecae5d9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# shuffle rows\n",
    "testable_sessions = testable_sessions.sample(frac=1).reset_index(drop=True)\n",
    "# add sessions randomly to validation set (0) or one of five CV splits (1-5)\n",
    "testable_sessions[\"split\"] = testable_sessions.index.values\n",
    "\n",
    "split_number_to_string = {\n",
    "    0: \"val\",  # 25% of sessions are validation\n",
    "    1: \"test\",\n",
    "    2: \"test\",\n",
    "    3: \"test\",\n",
    "}\n",
    "\n",
    "testable_sessions[\"split\"] = testable_sessions[\"split\"].apply(lambda x: x % 4).apply(lambda x: split_number_to_string[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de3c3bf",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# check if every row is a unique user session\n",
    "assert len(testable_sessions) == testable_sessions.user_session_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5a7db56962b5fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:47.570862Z",
     "start_time": "2024-05-11T14:15:42.162956Z"
    },
    "collapsed": false,
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of testable sessions in split train: 0\n",
      "number of testable sessions in split val: 630\n",
      "number of testable sessions in split test: 1887\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"number of testable sessions in split {split}: {len(testable_sessions[testable_sessions.split == split])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbd419df",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# map user_session_id to split\n",
    "user_session_id_to_split = {usid: split for usid, split in zip(testable_sessions.user_session_id.values, testable_sessions.split.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08597359",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# assign dataframe entries to split\n",
    "df[\"split\"] = df[\"user_session_id\"].apply(lambda x: user_session_id_to_split.get(x, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e904e68",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    17707.000000\n",
      "mean        13.555938\n",
      "std         47.063999\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          7.000000\n",
      "max       1251.000000\n",
      "Name: count, dtype: float64\n",
      "count    17707.000000\n",
      "mean         4.047495\n",
      "std          6.845939\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max        100.000000\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286/2464061315.py:9: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_df = train_df.groupby('item_id', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df.split == \"train\"]\n",
    "eval_df = df[df.split != \"train\"]\n",
    "\n",
    "# to simulate real-world data sparsity, we subsample rows of train df in a stratified manner (per item)\n",
    "# we modify the long-tail distribution to make it sparser\n",
    "# set count x of every item to x**(1/1.5)\n",
    "# max count will be 100, and the distribution will be long tailed\n",
    "print(train_df.item_id.value_counts().describe())\n",
    "train_df = train_df.groupby('item_id', group_keys=False).apply(\n",
    "    lambda x: x.sample(\n",
    "        min(\n",
    "            round(len(x)**(2/3)), # at most this number\n",
    "            100,  # at most 100\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "print(train_df.item_id.value_counts().describe())\n",
    "# in training split, keep only interactions with (positive) rating 1\n",
    "train_df = train_df[train_df.rating == 1.]\n",
    "\n",
    "df = pd.concat([train_df, eval_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c61e9",
   "metadata": {},
   "source": [
    "# everything up to here should be in preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec3bd8",
   "metadata": {},
   "source": [
    "## want df with 4 columns: user_session_id, item_id, rating, split\n",
    "## split = \"train\", \"val\", \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9666f041",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create user session enconding and item encoding\n",
    "user_session_id_to_idx = {user_session_id: idx for idx, user_session_id in enumerate(df['user_session_id'].unique())}\n",
    "user_session_idx_to_id = {idx: user_session_id for user_session_id, idx in user_session_id_to_idx.items()}\n",
    "\n",
    "item_id_to_idx = {item_id: idx for idx, item_id in enumerate(df['item_id'].unique())}\n",
    "item_idx_to_id = {idx: item_id for item_id, idx in item_id_to_idx.items()}\n",
    "\n",
    "# map values to idx using the above dicts\n",
    "df[\"user_session_id\"] = df[\"user_session_id\"].map(user_session_id_to_idx)\n",
    "df[\"item_id\"] = df[\"item_id\"].map(item_id_to_idx)\n",
    "\n",
    "# get number of unique user_sessions and unique items\n",
    "n_user_sessions = len(user_session_id_to_idx)\n",
    "n_items = len(item_id_to_idx)\n",
    "\n",
    "# instantiate dataset\n",
    "dataset = UserSessionItemDataset(df[df.split == \"train\"], df[df.split == \"val\"], df[df.split == \"test\"], n_user_sessions, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d753845d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 64.0\n",
      "Constructing G...\n",
      "Density of G: 0.2602%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.12433571090756053 +- 0.0032288946888075288\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.15731621433713747 +- 0.003960681190527962\n",
      "\n",
      "L2 256.0\n",
      "Constructing G...\n",
      "Density of G: 0.2602%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.13621958212610266 +- 0.0035343284602157724\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.15201580606250806 +- 0.003889969431115599\n",
      "\n",
      "L2 1024.0\n",
      "Constructing G...\n",
      "Density of G: 0.2602%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.14202295547934587 +- 0.0036919280183094227\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.14742060563336135 +- 0.0037845749129307815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l2s = [64., 256., 1024.,]\n",
    "\n",
    "hyperparameter_selection(dataset, l2s, ndcg, k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961644a",
   "metadata": {},
   "source": [
    "best L2 for EASE is 1024., for AbsEASE is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "823fb516",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split test\n",
      "EASE\n",
      "Constructing G...\n",
      "Density of G: 0.2602%\n",
      "Inverting G...\n",
      "pos_inputs\n",
      "recall_liked @ 10: 0.021957798436583284 +- 0.0006025498323860573\n",
      "recall_disliked @ 10: 0.0037197163668640223 +- 0.0007111707248753739\n",
      "ndcg @ 10: 0.04419161780892222 +- 0.0010531435119450429\n",
      "\n",
      "recall_liked @ 20: 0.040074191573059234 +- 0.0009339801814301079\n",
      "recall_disliked @ 20: 0.007239011656870498 +- 0.0009785943592240472\n",
      "ndcg @ 20: 0.06341842548492532 +- 0.0012832016468521449\n",
      "\n",
      "recall_liked @ 50: 0.0829221772596738 +- 0.0014458943619883944\n",
      "recall_disliked @ 50: 0.016319088794178604 +- 0.0014999023298077477\n",
      "ndcg @ 50: 0.10008262505917082 +- 0.0017115786003953318\n",
      "\n",
      "recall_liked @ 100: 0.13350399559199042 +- 0.0019848950690388996\n",
      "recall_disliked @ 100: 0.031201289995167254 +- 0.0020756187849005165\n",
      "ndcg @ 100: 0.13653119173083766 +- 0.0021492128201289745\n",
      "\n",
      "recall_liked @ 200: 0.20632883777280042 +- 0.0026118829415214795\n",
      "recall_disliked @ 200: 0.05519759408318342 +- 0.002734028090183357\n",
      "ndcg @ 200: 0.1818826468821465 +- 0.0026615137655046674\n",
      "\n",
      "recall_liked @ 500: 0.33554536201441904 +- 0.003480035090851405\n",
      "recall_disliked @ 500: 0.1109630572204727 +- 0.0038640477788656215\n",
      "ndcg @ 500: 0.2517531297712109 +- 0.003401279050201952\n",
      "\n",
      "\n",
      "pos_neg_inputs\n",
      "recall_liked @ 10: 0.0220563539759247 +- 0.0007074341539564696\n",
      "recall_disliked @ 10: 0.0034514822824047724 +- 0.0006857841290127912\n",
      "ndcg @ 10: 0.0437546394994869 +- 0.0010553916959464879\n",
      "\n",
      "recall_liked @ 20: 0.039782802946385455 +- 0.0009719769021319793\n",
      "recall_disliked @ 20: 0.007472962998732252 +- 0.0010153250911880728\n",
      "ndcg @ 20: 0.0627772701164343 +- 0.0012762525508402739\n",
      "\n",
      "recall_liked @ 50: 0.08159308329504093 +- 0.001445887537867214\n",
      "recall_disliked @ 50: 0.01616803255050192 +- 0.0014987751101495348\n",
      "ndcg @ 50: 0.09880580218333779 +- 0.0016947556667736155\n",
      "\n",
      "recall_liked @ 100: 0.13140805881953235 +- 0.0019696137986876623\n",
      "recall_disliked @ 100: 0.030529159537873177 +- 0.0020353106277540773\n",
      "ndcg @ 100: 0.1347936650925642 +- 0.0021407100589413237\n",
      "\n",
      "recall_liked @ 200: 0.20373609145076552 +- 0.002626269820781522\n",
      "recall_disliked @ 200: 0.054054971296230415 +- 0.0026782668114342482\n",
      "ndcg @ 200: 0.1795828155350921 +- 0.0026392849524178668\n",
      "\n",
      "recall_liked @ 500: 0.33284390590768653 +- 0.003436530773263289\n",
      "recall_disliked @ 500: 0.10898727737011368 +- 0.0038751448568512155\n",
      "ndcg @ 500: 0.24912284475769073 +- 0.0033784784203589784\n",
      "\n",
      "\n",
      "\n",
      "AbsEASE\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "EASE.fit() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m models \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEASE\u001b[39m\u001b[38;5;124m\"\u001b[39m, EASE, \u001b[38;5;241m1024.\u001b[39m), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbsEASE\u001b[39m\u001b[38;5;124m\"\u001b[39m, AbsEASE, \u001b[38;5;241m64.\u001b[39m)]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/recsys24-abs-ease/pipelines.py:90\u001b[0m, in \u001b[0;36mrun_test\u001b[0;34m(models, dataset, ks)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_test\u001b[39m(models, dataset, ks):\n\u001b[1;32m     71\u001b[0m     results_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     72\u001b[0m         model_name: {\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m         } \u001b[38;5;28;01mfor\u001b[39;00m model_name, _, _ \u001b[38;5;129;01min\u001b[39;00m models\n\u001b[1;32m     88\u001b[0m     }\n\u001b[0;32m---> 90\u001b[0m     \u001b[43mtrain_and_test_on_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results_dict\n",
      "File \u001b[0;32m~/recsys24-abs-ease/pipelines.py:42\u001b[0m, in \u001b[0;36mtrain_and_test_on_split\u001b[0;34m(models, dataset, split, ks, results_dict)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m     41\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(l2)\n\u001b[0;32m---> 42\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_type, input_matrix \u001b[38;5;129;01min\u001b[39;00m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_X_pos), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpos_neg_inputs\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_X)]:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(input_type)\n",
      "File \u001b[0;32m~/recsys24-abs-ease/models.py:39\u001b[0m, in \u001b[0;36mAbsEASE.fit\u001b[0;34m(self, X, density)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: sp\u001b[38;5;241m.\u001b[39mcsr_matrix, density\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msign(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB\u001b[38;5;241m.\u001b[39mdata)\n",
      "\u001b[0;31mTypeError\u001b[0m: EASE.fit() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "models = [(\"EASE\", EASE, 1024.), (\"AbsEASE\", AbsEASE, 64.)]\n",
    "\n",
    "run_test(models, dataset, ks=[10,20,50,100,200,500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
