{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:34.181452Z",
     "start_time": "2024-05-11T14:15:33.303017Z"
    },
    "collapsed": true,
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from dataset import UserSessionItemDataset\n",
    "from evaluation import recall, ndcg, evaluate\n",
    "from models import EASE, AbsEASE\n",
    "from pipelines import hyperparameter_selection, run_test\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b986879",
   "metadata": {},
   "source": [
    "# preprocessing = extract away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e499797bcae6bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:36.380565Z",
     "start_time": "2024-05-11T14:15:34.192085Z"
    },
    "collapsed": false,
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>datetime</th>\n",
       "      <th>sessionId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1439472199</td>\n",
       "      <td>2015-08-13 13:23:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1439472203</td>\n",
       "      <td>2015-08-13 13:23:23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1439472215</td>\n",
       "      <td>2015-08-13 13:23:35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>480</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1439472219</td>\n",
       "      <td>2015-08-13 13:23:39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2571</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1439472221</td>\n",
       "      <td>2015-08-13 13:23:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  item_id  rating   timestamp             datetime  sessionId\n",
       "0       3      356     1.0  1439472199  2015-08-13 13:23:19          1\n",
       "1       3      593     1.0  1439472203  2015-08-13 13:23:23          1\n",
       "2       3        1     1.0  1439472215  2015-08-13 13:23:35          1\n",
       "3       3      480    -1.0  1439472219  2015-08-13 13:23:39          1\n",
       "4       3     2571     1.0  1439472221  2015-08-13 13:23:41          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FOLDER = 'data/'\n",
    "\n",
    "df = pd.read_csv(DATA_FOLDER + 'processedRatingsMovielens.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df.rename(columns={\"movieId\": \"item_id\"})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bff4d4d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create a user_session identifier\n",
    "df['user_session_id'] = (df['userId'].astype(str) + '_' + df['sessionId'].astype(str)).map(hash)\n",
    "df = df.sort_values(by=['user_session_id', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46afc347",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283453, 47889, 4644545)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.user_session_id.nunique(), df.item_id.nunique(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28d509fc",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>sessionId</th>\n",
       "      <th>minValue</th>\n",
       "      <th>maxValue</th>\n",
       "      <th>ratingsCount</th>\n",
       "      <th>positiveCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>259</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  sessionId  minValue  maxValue  ratingsCount  positiveCount\n",
       "0       3          1      -1.0       1.0           259            248\n",
       "1       3          3      -1.0       1.0            33             31\n",
       "2       3          5      -1.0       1.0            53             52\n",
       "3       4          1      -1.0       1.0           138            100\n",
       "4       4          3      -1.0       1.0             5              2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testable_sessions = pd.read_csv(DATA_FOLDER + 'testableSessionsMovielens.csv')\n",
    "\n",
    "testable_sessions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f38e764",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63054"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testable_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "335f5874",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34112"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(testable_sessions.positiveCount.min())\n",
    "# we need at least 5 positive interactions and 5 negative interactions\n",
    "testable_sessions[\"negativeCount\"] = testable_sessions[\"ratingsCount\"] - testable_sessions[\"positiveCount\"]\n",
    "testable_sessions = testable_sessions[(testable_sessions.positiveCount >= 3) & (testable_sessions.negativeCount >= 3)]\n",
    "len(testable_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3abef52",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create a user_session identifier\n",
    "testable_sessions['user_session_id'] = (testable_sessions['userId'].astype(str) + '_' + testable_sessions['sessionId'].astype(str)).map(hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecae5d9",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# shuffle rows\n",
    "testable_sessions = testable_sessions.sample(frac=1).reset_index(drop=True)\n",
    "# add sessions randomly to validation set (0) or one of five CV splits (1-5)\n",
    "testable_sessions[\"split\"] = testable_sessions.index.values\n",
    "\n",
    "split_number_to_string = {\n",
    "    0: \"val\",  # 25% of sessions are validation\n",
    "    1: \"test\",\n",
    "    2: \"test\",\n",
    "    3: \"test\",\n",
    "}\n",
    "\n",
    "testable_sessions[\"split\"] = testable_sessions[\"split\"].apply(lambda x: x % 4).apply(lambda x: split_number_to_string[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de3c3bf",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# check if every row is a unique user session\n",
    "assert len(testable_sessions) == testable_sessions.user_session_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5a7db56962b5fd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-11T14:15:47.570862Z",
     "start_time": "2024-05-11T14:15:42.162956Z"
    },
    "collapsed": false,
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of testable sessions in split train: 0\n",
      "number of testable sessions in split test: 25584\n",
      "number of testable sessions in split val: 8528\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"val\", \"test\"]:\n",
    "    print(f\"number of testable sessions in split {split}: {len(testable_sessions[testable_sessions.split == split])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd419df",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# map user_session_id to split\n",
    "user_session_id_to_split = {usid: split for usid, split in zip(testable_sessions.user_session_id.values, testable_sessions.split.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08597359",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# assign dataframe entries to split\n",
    "df[\"split\"] = df[\"user_session_id\"].apply(lambda x: user_session_id_to_split.get(x, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e876253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df.split == \"train\"]\n",
    "eval_df = df[df.split != \"train\"]\n",
    "\n",
    "# to simulate real-world data sparsity, we subsample rows of train df in a stratified manner (per item)\n",
    "# we modify the long-tail distribution to make it sparser\n",
    "# set count x of every item to x**(1/1.5)\n",
    "# max count will be 100, and the distribution will be long tailed\n",
    "print(train_df.item_id.value_counts().describe())\n",
    "train_df = train_df.groupby('item_id', group_keys=False).apply(\n",
    "    lambda x: x.sample(\n",
    "        min(\n",
    "            round(len(x)**(2/3)), # at most this number\n",
    "            100,  # at most 100\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "print(train_df.item_id.value_counts().describe())\n",
    "# in training split, keep only interactions with (positive) rating 1\n",
    "train_df = train_df[train_df.rating == 1.]\n",
    "\n",
    "df = pd.concat([train_df, eval_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51c8c55",
   "metadata": {},
   "source": [
    "# everything up to here should be in preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a587297",
   "metadata": {},
   "source": [
    "## want df with 4 columns: user_session_id, item_id, rating, split\n",
    "## split = \"train\", \"val\", \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9666f041",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# create user session enconding and item encoding\n",
    "user_session_id_to_idx = {user_session_id: idx for idx, user_session_id in enumerate(df['user_session_id'].unique())}\n",
    "user_session_idx_to_id = {idx: user_session_id for user_session_id, idx in user_session_id_to_idx.items()}\n",
    "\n",
    "item_id_to_idx = {item_id: idx for idx, item_id in enumerate(df['item_id'].unique())}\n",
    "item_idx_to_id = {idx: item_id for item_id, idx in item_id_to_idx.items()}\n",
    "\n",
    "# map values to idx using the above dicts\n",
    "df[\"user_session_id\"] = df[\"user_session_id\"].map(user_session_id_to_idx)\n",
    "df[\"item_id\"] = df[\"item_id\"].map(item_id_to_idx)\n",
    "\n",
    "# get number of unique user_sessions and unique items\n",
    "n_user_sessions = len(user_session_id_to_idx)\n",
    "n_items = len(item_id_to_idx)\n",
    "\n",
    "# instantiate dataset\n",
    "dataset = UserSessionItemDataset(df[df.split == \"train\"], df[df.split == \"val\"], df[df.split == \"test\"], n_user_sessions, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d753845d",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    36130.000000\n",
      "mean        49.365652\n",
      "std        330.643594\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          8.000000\n",
      "max      11858.000000\n",
      "Name: count, dtype: float64\n",
      "count    36130.000000\n",
      "mean         6.269278\n",
      "std         14.097070\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max        100.000000\n",
      "Name: count, dtype: float64\n",
      "L2 64.0\n",
      "Constructing G...\n",
      "Density of G: 0.8001%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.10280952670767177 +- 0.0012600981500890316\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.11178004817350767 +- 0.0013456606083697574\n",
      "\n",
      "L2 256.0\n",
      "Constructing G...\n",
      "Density of G: 0.8001%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.10530491136784129 +- 0.0012859555385763435\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.10755692755377347 +- 0.0013110915169290455\n",
      "\n",
      "L2 1024.0\n",
      "Constructing G...\n",
      "Density of G: 0.8001%\n",
      "Inverting G...\n",
      "EASE\n",
      "ndcg @ 100: 0.1047011335780279 +- 0.0012814963006538436\n",
      "AbsEASE\n",
      "ndcg @ 100: 0.10481405901070356 +- 0.0012883569133610212\n",
      "\n"
     ]
    }
   ],
   "source": [
    "l2s = [64., 256., 1024.,]\n",
    "\n",
    "hyperparameter_selection(dataset, l2s, ndcg, k=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961644a",
   "metadata": {},
   "source": [
    "best L2 for EASE is 256., for AbsEASE is 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "823fb516",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split test\n",
      "count    36130.000000\n",
      "mean        49.365652\n",
      "std        330.643594\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          8.000000\n",
      "max      11858.000000\n",
      "Name: count, dtype: float64\n",
      "count    36130.000000\n",
      "mean         6.269278\n",
      "std         14.097070\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          2.000000\n",
      "75%          4.000000\n",
      "max        100.000000\n",
      "Name: count, dtype: float64\n",
      "EASE\n",
      "Constructing G...\n",
      "Density of G: 0.7978%\n",
      "Inverting G...\n",
      "pos_inputs\n",
      "recall_liked @ 10: 0.02556310647019935 +- 0.00026663082914651426\n",
      "recall_disliked @ 10: 0.009355076677092898 +- 0.0002899340020287073\n",
      "ndcg @ 10: 0.035653033045322295 +- 0.000400107480865015\n",
      "\n",
      "recall_liked @ 20: 0.044817717075154154 +- 0.00035459659067071817\n",
      "recall_disliked @ 20: 0.01779817804334826 +- 0.0003967999331259308\n",
      "ndcg @ 20: 0.0493454844877149 +- 0.0004646559189535226\n",
      "\n",
      "recall_liked @ 50: 0.09075923608341364 +- 0.0005210615471871608\n",
      "recall_disliked @ 50: 0.04244437074032526 +- 0.0006137069773672246\n",
      "ndcg @ 50: 0.07471525091361857 +- 0.0005829311418126086\n",
      "\n",
      "recall_liked @ 100: 0.14990502108727333 +- 0.0007087180345098825\n",
      "recall_disliked @ 100: 0.07688715001233568 +- 0.0008260646300400763\n",
      "ndcg @ 100: 0.10166765457513112 +- 0.000715731124525404\n",
      "\n",
      "recall_liked @ 200: 0.23669889263607582 +- 0.0009666401165611774\n",
      "recall_disliked @ 200: 0.13522574052336667 +- 0.0010957183567664205\n",
      "ndcg @ 200: 0.13488555453611764 +- 0.0009046321730579532\n",
      "\n",
      "recall_liked @ 500: 0.38952432664210423 +- 0.0013676730802165639\n",
      "recall_disliked @ 500: 0.2545916445993906 +- 0.0014877845821342564\n",
      "ndcg @ 500: 0.1819366447708041 +- 0.0012211922876804245\n",
      "\n",
      "\n",
      "pos_neg_inputs\n",
      "recall_liked @ 10: 0.024632533341024384 +- 0.0002628213442124003\n",
      "recall_disliked @ 10: 0.008693803440122064 +- 0.00028277209767901064\n",
      "ndcg @ 10: 0.03501418590107192 +- 0.00038831930222238756\n",
      "\n",
      "recall_liked @ 20: 0.04282068058664896 +- 0.00034869151107085484\n",
      "recall_disliked @ 20: 0.01650829493859127 +- 0.0003923159138455431\n",
      "ndcg @ 20: 0.048387110445314824 +- 0.0004463210518884737\n",
      "\n",
      "recall_liked @ 50: 0.08675257686670271 +- 0.0005101461525427128\n",
      "recall_disliked @ 50: 0.03830577781093732 +- 0.0005915713175179278\n",
      "ndcg @ 50: 0.07375931166924318 +- 0.0005557148865507874\n",
      "\n",
      "recall_liked @ 100: 0.14228989516345006 +- 0.000684814757144542\n",
      "recall_disliked @ 100: 0.06981592512667724 +- 0.0007923613846637487\n",
      "ndcg @ 100: 0.09998036439929962 +- 0.0006798128071431718\n",
      "\n",
      "recall_liked @ 200: 0.22305882350267445 +- 0.000923536977998585\n",
      "recall_disliked @ 200: 0.119950220993624 +- 0.001037303271177028\n",
      "ndcg @ 200: 0.13290265748676414 +- 0.0008479800922195538\n",
      "\n",
      "recall_liked @ 500: 0.3646240826150089 +- 0.001284048608929674\n",
      "recall_disliked @ 500: 0.22655199217020855 +- 0.0013903307628236453\n",
      "ndcg @ 500: 0.17834362737300577 +- 0.001126805051614424\n",
      "\n",
      "\n",
      "\n",
      "AbsEASE\n",
      "Constructing G...\n",
      "Density of G: 0.7978%\n",
      "Inverting G...\n",
      "pos_inputs\n",
      "recall_liked @ 10: 0.02645769187228327 +- 0.00026989818120581036\n",
      "recall_disliked @ 10: 0.009287416808123882 +- 0.00028926382265129143\n",
      "ndcg @ 10: 0.03717928056120555 +- 0.0004060641023702916\n",
      "\n",
      "recall_liked @ 20: 0.04632758556430349 +- 0.0003623299362424753\n",
      "recall_disliked @ 20: 0.018294875680519376 +- 0.00040346444311260295\n",
      "ndcg @ 20: 0.05125827175175085 +- 0.0004749269789261471\n",
      "\n",
      "recall_liked @ 50: 0.09587215227374192 +- 0.0005373583654491707\n",
      "recall_disliked @ 50: 0.044319356728865604 +- 0.0006262761455726246\n",
      "ndcg @ 50: 0.0783929784696132 +- 0.0006012020433069968\n",
      "\n",
      "recall_liked @ 100: 0.16167419503318953 +- 0.0007437011561926044\n",
      "recall_disliked @ 100: 0.08284923641318122 +- 0.0008625073025472641\n",
      "ndcg @ 100: 0.10788767846570566 +- 0.0007476141458084832\n",
      "\n",
      "recall_liked @ 200: 0.2679472803263183 +- 0.0010494603026623927\n",
      "recall_disliked @ 200: 0.1534604744105978 +- 0.001180829626664333\n",
      "ndcg @ 200: 0.14707628356167346 +- 0.0009736427565782024\n",
      "\n",
      "recall_liked @ 500: 0.48901175950257464 +- 0.0015589796901430883\n",
      "recall_disliked @ 500: 0.3329811573367025 +- 0.0017336858480932987\n",
      "ndcg @ 500: 0.2079431451820448 +- 0.001414430354826085\n",
      "\n",
      "\n",
      "pos_neg_inputs\n",
      "recall_liked @ 10: 0.025068043375110597 +- 0.0002602738989928218\n",
      "recall_disliked @ 10: 0.008095190207767645 +- 0.00027990721157540225\n",
      "ndcg @ 10: 0.03771969643458378 +- 0.0003844083823404569\n",
      "\n",
      "recall_liked @ 20: 0.04368465707956409 +- 0.0003467785222337426\n",
      "recall_disliked @ 20: 0.015741239655326127 +- 0.00038646049282541783\n",
      "ndcg @ 20: 0.052122386222279576 +- 0.00044336520903503205\n",
      "\n",
      "recall_liked @ 50: 0.08895451555283161 +- 0.0005210114811998461\n",
      "recall_disliked @ 50: 0.03641995992696236 +- 0.00058942399046063\n",
      "ndcg @ 50: 0.08007601862933864 +- 0.0005553053363827633\n",
      "\n",
      "recall_liked @ 100: 0.14777517151165045 +- 0.0007259848831154479\n",
      "recall_disliked @ 100: 0.06744376983140622 +- 0.0008052629358856555\n",
      "ndcg @ 100: 0.11007911581054823 +- 0.0006852097396302968\n",
      "\n",
      "recall_liked @ 200: 0.24001057320426897 +- 0.001035410942186298\n",
      "recall_disliked @ 200: 0.12179913661621138 +- 0.001094598242154568\n",
      "ndcg @ 200: 0.1503409576059356 +- 0.0008735134493883145\n",
      "\n",
      "recall_liked @ 500: 0.42305848289963305 +- 0.0015737780305257868\n",
      "recall_disliked @ 500: 0.2568695431569571 +- 0.0016261134023897834\n",
      "ndcg @ 500: 0.2151896978527832 +- 0.0011863703922833776\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = [(\"EASE\", EASE, 256.), (\"AbsEASE\", AbsEASE, 64.)]\n",
    "\n",
    "run_test(models, dataset, ks=[10,20,50,100,200,500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
